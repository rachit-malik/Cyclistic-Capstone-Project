---
title: "Cyclistic Bike-Share Analysis Capstone"
author: "Rachit Malik"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# Load required libraries
library(tidyverse)
library(skimr)
library(janitor)
library(lubridate)
# scales is used for axis/label formatting - it's typically installed with tidyverse
# If not installed, uncomment the next line to install:
# install.packages("scales")
library(scales)
options(scipen = 999)
```

# Introduction

This R Markdown documents an end-to-end analysis for the **Cyclistic Bike-Share** capstone: reading and stacking monthly CSV files, cleaning and enriching the data, computing summary statistics, and producing visualizations that compare member and casual riders.

> Make sure your CSV files are in the folder: `C:/Users/a2z/Downloads/Cyclistic` (or update `file_paths` below to the correct location).

# 1. Import and merge data

```{r import-merge}
# List CSV files in the folder
file_paths <- list.files("C:/Users/a2z/Downloads/Cyclistic", pattern = "\\.csv$", full.names = TRUE)

# Read all files and row-bind them into a single tibble
all_trips <- file_paths %>%
  map_dfr(read_csv)

# Quick peek
glimpse(all_trips)
head(all_trips)
```

# 2. Initial checks

```{r initial-checks}
# If you have a large dataset, use skim to get a compact summary
skim_without_charts(all_trips)

# Check for obvious issues: missing columns that we expect
expected_cols <- c("ride_id", "started_at", "ended_at", "start_station_name", "member_casual")
setdiff(expected_cols, colnames(all_trips))
```

# 3. Clean column names and drop empty / duplicate rows

```{r clean-names}
all_trips_v2 <- all_trips %>%
  clean_names() %>%                # standardise column names to snake_case
  drop_na() %>%                    # remove rows with any NA values (use with caution)
  distinct(ride_id, .keep_all = TRUE) # remove duplicate rides if present

# confirm
glimpse(all_trips_v2)
```

> **Note:** `drop_na()` removes *any* row with an NA. If you'd prefer to only remove rows missing key columns (e.g., `started_at` or `ended_at`), replace `drop_na()` with `drop_na(started_at, ended_at, ride_id)`.

# 4. Add calculated columns

```{r mutate-columns}
all_trips_v2 <- all_trips_v2 %>%
  mutate(
    # calculate ride length in minutes (ensure started_at / ended_at are POSIXct)
    started_at = as_datetime(started_at),
    ended_at   = as_datetime(ended_at),
    ride_length = as.numeric(difftime(ended_at, started_at, units = "mins")),

    # extract day, month, year for aggregation
    day_of_week = wday(started_at, label = TRUE, abbr = FALSE),
    month = month(started_at, label = TRUE, abbr = FALSE),
    year = year(started_at)
  )

# quick summary of ride_length
summary(all_trips_v2$ride_length)
```

# 5. Filter out invalid or administrative rides

```{r filter-bad-data}
all_trips_clean <- all_trips_v2 %>%
  filter(ride_length > 1,            # remove false starts
         ride_length < 1440,         # remove rides > 24 hours
         start_station_name != "HQ QR") # remove test/admin rides

# confirm cleaned row counts
nrow(all_trips_v2)
nrow(all_trips_clean)
```

# 6. Summary statistics by user type

```{r summary-stats}
summary_stats <- all_trips_clean %>%
  group_by(member_casual) %>%
  summarise(
    average_duration = mean(ride_length, na.rm = TRUE),
    median_duration = median(ride_length, na.rm = TRUE),
    max_duration = max(ride_length, na.rm = TRUE),
    total_rides = n(),
    .groups = "drop"
  )

print(summary_stats)
```

# 7. Daily usage patterns (member vs casual)

```{r daily-usage}
daily_usage <- all_trips_clean %>%
  group_by(member_casual, day_of_week) %>%
  summarise(
    number_of_rides = n(),
    average_duration = mean(ride_length, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(member_casual, day_of_week)

print(daily_usage)

# bar chart comparing days
ggplot(data = daily_usage) +
  aes(x = day_of_week, y = number_of_rides, fill = member_casual) +
  geom_col(position = "dodge") +
  labs(title = "Total Rides per Day: Member vs Casual",
       y = "Number of Rides", x = "Day of Week") +
  scale_y_continuous(labels = scales::comma) +
  theme_minimal()
```

# 8. Rider type distribution (pie chart)

```{r rider-distribution, fig.width=6, fig.height=5}
user_dist <- all_trips_clean %>%
  count(member_casual) %>%
  mutate(perc = n / sum(n), labels = scales::percent(perc))

# pie chart
ggplot(user_dist, aes(x = "", y = perc, fill = member_casual)) +
  geom_col(color = "white") +
  coord_polar(theta = "y") +
  geom_text(aes(label = labels), position = position_stack(vjust = 0.5)) +
  theme_void() +
  labs(title = "Distribution of Rider Types", fill = "Rider Type")
```

# 9. Monthly ride trends

```{r monthly-trend}
monthly_trend <- all_trips_clean %>%
  mutate(month = floor_date(started_at, "month")) %>%
  group_by(month, member_casual) %>%
  summarise(number_of_rides = n(), .groups = "drop")

# line plot
ggplot(monthly_trend, aes(x = month, y = number_of_rides, color = member_casual)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Monthly Ride Trends",
       subtitle = "Casual riders peak significantly in summer months",
       x = "Month", y = "Number of Rides") +
  theme_minimal()
```

# 10. Export cleaned data

```{r export-clean}
write_csv(all_trips_clean, "C:/Users/a2z/Downloads/cyclistic_final_cleaned_data.csv")
```

# 11. Suggested next steps

- Add checks for timezone inconsistencies and ensure `started_at`/`ended_at` parse correctly.
- Consider creating `ride_length_minutes` categories (e.g., short: <10, medium: 10-60, long: >60) for segmentation.
- Compare trip distances (if available) vs ride duration to detect e-bikes or other anomalies.
- Add interactive visualizations using `plotly` or build a small Shiny app to explore segments.

# Session info

```{r session-info, echo = FALSE}
sessionInfo()